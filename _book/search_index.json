[["data-exploration.html", "Home Work 1 Principles of Statistical Data Analysis 1 Data Exploration 1.1 Data Summary: 1.2 Data Visualization", " Home Work 1 Principles of Statistical Data Analysis Jiacheng Shen Sajjad Ayashm 2024-10-28 1 Data Exploration In this section, we explore the data using summary statistics and visualizations to understand the distribution of ant abundance and soil moisture. Table 1.1 shows 5 rows of our data. Table 1.1: Data in ants.RData file abundance moisture 2 20.0 226 17.6 52 12.2 37 15.6 0 20.5 255 20.5 1.1 Data Summary: Table 1.2 shows the first few rows of the data set. Table 1.2: Summary of Abundance of Ants and Moisture of Soil Min. 1st Qu. Median Mean 3rd Qu. Max. Abundance 0.00 6.75 35.50 86.31 99.25 767.00 Moisture 12.0 15.4 17.9 17.5 19.9 21.5 Additionally, the variance of ant abundance in the sample is 1.99e+04, and for moisture, it is 7.083 1.2 Data Visualization We visualized the distribution of ant abundance using a histogram (Figure 1.1) and boxplot (Figure 1.2) to identify its spread and any potential outliers. A scatter plot of soil moisture versus ant abundance (Figure 1.3) was created to explore their relationship. Additionally, a mean-variance plot (Figure 1.4) was used to assess overdispersion, which supports the choice of a negative binomial model for this data. Figure 1.1: Histogram of Ant Abundance Figure 1.2: Boxplot of Abundance Figure 1.3: Scatter Plot of Moisture vs Ant Abundance Figure 1.4: Mean vs Variance of Ant Abundance "],["likelihood-function.html", "2 Likelihood Function 2.1 Likelihood Function 2.2 Log-Likelihood Function", " 2 Likelihood Function The likelihood function is shown in Equation. \\[ L(\\beta_0, \\beta_1, \\phi) = \\prod_{i=1}^n \\frac{\\Gamma(y_i + 1 / \\phi)}{\\Gamma(1 / \\phi) \\, y_i!} \\left( \\frac{1}{1 + \\mu_i \\phi} \\right)^{1 / \\phi} \\left( \\frac{\\mu_i \\phi}{1 + \\mu_i \\phi} \\right)^{y_i} \\] 2.1 Likelihood Function To define the likelihood function in R, we use a function that computes the product of probabilities for all observations. # Define the likelihood function likelihood_function &lt;- function(params, abundance, moisture) { beta_0 &lt;- params[1] # The intercept parameter beta_1 &lt;- params[2] # The coefficient for moisture phi &lt;- params[3] # The overdispersion parameter # Calculate the mean (mu) for each observation mu &lt;- exp(beta_0 + beta_1 * moisture) # Compute the negative binomial likelihood for each observation likelihoods &lt;- dnbinom(abundance, size = 1/phi, mu = mu, log = FALSE) # Calculate the total likelihood by multiplying individual likelihoods total_likelihood &lt;- prod(likelihoods) return(total_likelihood) } initial_params &lt;- c(1, 0.1, 0.5) # Example starting values for beta_0, beta_1, and phi likelihood_value &lt;- likelihood_function(initial_params, ants$abundance, ants$moisture) Note: If we use the set of parameters described in the example above, the likelihood value results 0. One possible reason is that the number is too small to exhibit. That’s why we derive the following log likelihood function. 2.2 Log-Likelihood Function The log-likelihood function computes the sum of the log-probabilities instead of multiplying the probabilities directly, providing more numerical stability. # Define the log-likelihood function log_likelihood &lt;- function(params, abundance, moisture) { beta_0 &lt;- params[1] # The intercept parameter beta_1 &lt;- params[2] # The coefficient for moisture phi &lt;- params[3] # The overdispersion parameter # Calculate the mean (mu) for each observation mu &lt;- exp(beta_0 + beta_1 * moisture) # Compute the log-likelihood for each observation log_lik &lt;- sum( lgamma(abundance + 1 / phi) - lgamma(1 / phi) - lgamma(abundance + 1) + (1 / phi) * log(1 / (1 + mu * phi)) + abundance * log(mu * phi / (1 + mu * phi)) ) return(log_lik) # Return the log-likelihood } initial_params &lt;- c(1, 0.1, 0.5) # Example starting values for beta_0, beta_1, and phi log_likelihood_value &lt;- log_likelihood(initial_params, ants$abundance, ants$moisture) Using the same set of parameters, the log likelihood values result -1148.303, which makes more sense. Explanation: Likelihood vs. Log-Likelihood: The likelihood function directly computes the product of individual probabilities, which can lead to underflow when dealing with very small values. The log-likelihood function sums the logarithms of the probabilities, providing greater numerical stability. "],["estimating-equation-for-beta_1.html", "3 Estimating Equation for \\(\\beta_1\\) 3.1 Step 1: Negative Log-Likelihood Function 3.2 Step 2: Perform Optimization to Estimate Parameters", " 3 Estimating Equation for \\(\\beta_1\\) Our objective is to derive the estimating equation for \\(\\beta_1\\) by maximizing the log-likelihood function. The maximum likelihood estimate (MLE) for \\(\\beta_1\\) can be obtained by setting the derivative of the log-likelihood with respect to \\(\\beta_1\\) to zero, which requires numerical optimization. The log-likelihood function is given by: \\[ \\ell(\\beta_0, \\beta_1, \\phi) = \\sum_{i=1}^n \\left[ \\log \\left( \\Gamma(y_i + \\frac{1}{\\phi}) \\right) - \\log \\left( \\Gamma(\\frac{1}{\\phi}) \\right) - \\log(y_i!) + \\frac{1}{\\phi} \\log \\left( \\frac{1}{1 + \\exp(\\beta_0 + \\beta_1 x_i) \\phi} \\right) + y_i \\log \\left( \\frac{\\exp(\\beta_0 + \\beta_1 x_i) \\phi}{1 + \\exp(\\beta_0 + \\beta_1 x_i) \\phi} \\right) \\right] \\] To find the estimating equation for \\(\\beta_1\\), we differentiate this log-likelihood with respect to \\(\\beta_1\\): \\[ \\ell(\\beta_1) = \\sum_{i=1}^n \\left[ \\frac{1}{\\phi} \\log \\left( \\frac{1}{1 + \\exp(\\beta_0 + \\beta_1 x_i) \\phi} \\right) + y_i \\log \\left( \\frac{\\exp(\\beta_0 + \\beta_1 x_i) \\phi}{1 + \\exp(\\beta_0 + \\beta_1 x_i) \\phi} \\right) \\right] \\] Differentiating both terms with respect to \\(\\beta_1\\) yields: \\[ \\frac{\\partial \\ell(\\beta_1)}{\\partial \\beta_1} = \\sum_{i=1}^n \\left[ \\frac{x_i \\left( y_i - \\exp(\\beta_0 + \\beta_1 x_i) \\right)}{1 + \\exp(\\beta_0 + \\beta_1 x_i) \\phi} \\right] \\] Setting this result equal to zero gives the estimating equation: \\[ \\sum_{i=1}^n \\left[ \\frac{x_i \\left( y_i - \\exp(\\beta_0 + \\beta_1 x_i) \\right)}{1 + \\exp(\\beta_0 + \\beta_1 x_i) \\phi} \\right] = 0 \\] 3.1 Step 1: Negative Log-Likelihood Function Since the optim() function in R minimizes functions, we use the negative log-likelihood function for the optimization process. The negative log-likelihood is simply the negative of the log-likelihood function. # Define the negative log-likelihood function for optimization neg_log_likelihood &lt;- function(params) { -log_likelihood(params, ants$abundance, ants$moisture) } 3.2 Step 2: Perform Optimization to Estimate Parameters We now use the optim() function to find the maximum likelihood estimates (MLE) for \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\phi\\). The initial guesses for the parameters are provided, and the optimization is performed using the BFGS method. # Initial parameter guesses: beta_0 = 1, beta_1 = 0.1, phi = 0.5 initial_params &lt;- c(1, 0.1, 0.5) # Perform optimization to estimate beta_0, beta_1, and phi optim_result &lt;- optim(initial_params, neg_log_likelihood, method = &quot;BFGS&quot;) ## Warning in log(1/(1 + mu * phi)): NaNs produced # Extract the estimated parameters estimated_params &lt;- optim_result$par # Assign the estimates to beta_0_hat, beta_1_hat, and phi_hat beta_0_hat &lt;- estimated_params[1] beta_1_hat &lt;- estimated_params[2] phi_hat &lt;- estimated_params[3] The estimated parameters provide insights into the relationship between soil moisture and ant abundance. The intercept (\\(\\beta_0\\)) is 2.504, representing baseline abundance, while the coefficient for moisture (\\(\\beta_1\\)) at 0.109 shows the effect of soil moisture. The overdispersion parameter (\\(\\phi\\)) at 2.288 captures additional variability in the data. "],["log-likelihood-optimization-with-respect-to-beta_1.html", "4 Log-Likelihood Optimization with Respect to \\(\\beta_1\\)", " 4 Log-Likelihood Optimization with Respect to \\(\\beta_1\\) In this question, we explore the relationship between \\(\\beta_1\\) and the log-likelihood function, given the parameter estimates for \\(\\beta_0\\) and \\(\\phi\\). Our objective is to visualize how changes in \\(\\beta_1\\) affect the log-likelihood, helping us understand its influence on the model. # Given values beta0 &lt;- 2.509067 phi &lt;- 2.289377 x_data &lt;- ants$moisture # Observed soil moisture data y_data &lt;- ants$abundance # Observed ant abundance data # Define the log-likelihood function in terms of beta1 log_likelihood &lt;- function(beta1) { mu &lt;- exp(beta0 + beta1 * x_data) sum(dnbinom(y_data, size = 1/phi, mu = mu, log = TRUE)) } # Define a range of beta1 values beta1_values &lt;- seq(-5, 5, length.out = 100) # Compute the log-likelihood for each beta1 value log_likelihood_values &lt;- sapply(beta1_values, log_likelihood) In the Figure 4.1 above, we observe the log-likelihood values across a range of \\(\\beta_1\\) values. The peak of this curve indicates the value of that maximizes the log-likelihood, corresponding to the most likely estimate of\\(\\beta_1\\) given the data. This visualization aids in understanding how sensitive the model’s fit is to changes in \\(\\beta_1\\). # Plot the log-likelihood function plot(beta1_values, log_likelihood_values, type = &quot;l&quot;, xlab = expression(beta[1]), ylab = &quot;Log-Likelihood&quot;, main = &quot;Log-Likelihood as a function of Beta1&quot;) Figure 4.1: Log likelihood as a function of beta 1 "],["estimating-the-optimal-value-of-beta_1.html", "5 Estimating the Optimal Value of \\(\\beta_1\\)", " 5 Estimating the Optimal Value of \\(\\beta_1\\) To estimate the optimal value of \\(\\beta_1\\) that maximizes the log-likelihood, we use the optim() function in R with the BFGS optimization method: # Optimize to find beta1 result &lt;- optim(par = 0, fn = log_likelihood, control = list(fnscale = -1), method = &quot;BFGS&quot;) # Extract the estimated beta1 beta1_estimate &lt;- result$par The estimated value of \\(\\beta_1\\) is 0.109, which provides the most likely parameter value based on the observed data and model assumptions. "],["evaluating-the-estimating-equation-at-beta_1.html", "6 Evaluating the Estimating Equation at \\(\\beta_1\\)", " 6 Evaluating the Estimating Equation at \\(\\beta_1\\) To verify the estimated \\(\\beta_1\\) value from Question 5, we compute the estimating equation at \\(\\beta_1\\) to see if it approximates zero, as expected for a maximum likelihood estimate. # Define the estimating equation function estimating_equation &lt;- function(beta1, beta0, phi, x, y) { sum(x * (y - exp(beta0 + beta1 * x)) / (1 + exp(beta0 + beta1 * x) * phi)) } # Calculate the value of the estimating equation at beta1_estimate result &lt;- estimating_equation(beta1_estimate, beta0, phi, x_data, y_data) The resulting value of the estimating equation is -0.017. A result close to zero suggests that \\(\\beta_1\\) is indeed an optimal estimate, indicating that the observed data align well with the expected values under the model. "],["visualizing-the-mean-variance-relationship.html", "7 Visualizing the Mean-Variance Relationship 7.1 Step 1: Calculating Predicted Mean and Variance 7.2 Step 2: Plotting the Predicted Mean-Variance Relationship 7.3 Step 3: Comparing with Observed Data 7.4 Interpretation", " 7 Visualizing the Mean-Variance Relationship In this question, we use the estimated parameters to visualize the mean-variance relationship of predicted ant abundance and compare it to the observed data from Question 1. 7.1 Step 1: Calculating Predicted Mean and Variance Using the model’s estimated parameters, we calculate the predicted mean and variance of ant abundance for each soil moisture observation. # Estimated parameters from optimization beta0 &lt;- beta_0_hat beta1 &lt;- beta_1_hat phi &lt;- phi_hat # Calculate the predicted mean (mu) and corresponding variance predicted_mean &lt;- exp(beta0 + beta1 * x_data) # Predicted mean for ant abundance predicted_variance &lt;- predicted_mean + (predicted_mean^2) * phi # Predicted variance based on the negative binomial model 7.2 Step 2: Plotting the Predicted Mean-Variance Relationship We plot the predicted mean against the predicted variance to visualize the model’s mean-variance relationship for ant abundance. (Figure 7.1) Figure 7.1: Mean-Variance Relationship of Predicted Ant Abundance 7.3 Step 3: Comparing with Observed Data To evaluate the model fit, we overlay the actual mean-variance relationship from the observed data (calculated in Question 1) on the same plot. (Figure 7.2) Figure 7.2: Mean-Variance Relationship of Predicted Ant Abundance 7.4 Interpretation The plot shows the relationship between the mean and variance of the predicted abundance (in blue) and the actual observed data (in red). If the predicted values closely match the observed data, this suggests that the model’s mean-variance relationship aligns well with the data, supporting the negative binomial model’s appropriateness. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
